A1:
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler, LabelEncoder

df = pd.read_csv('/demo1.csv')

df.head()
df.tail()
df.shape
df.columns
df.info()
df.describe()
df.isnull().sum()
df.dtypes

df.iloc[0:5]
df.iloc[0:5, 0:3] 
df.loc[0:4]
df.loc[:, 'placement offer count']

scaler = MinMaxScaler()
numeric_cols = ['math score', 'reading score', 'writing score', 'placement score', 'placement offer count']
df[numeric_cols] = scaler.fit_transform(df[numeric_cols])

df[numeric_cols].iloc[0:4]
df.info()
df.head()
df.tail()

==============================================================

A2:
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder

missing_values = ["Na", "na"]


df = pd.read_csv("/home/gescoe/Desktop/DSBDA_25B/StudentsPerformanceTest1(1).csv", na_values=missing_values)

df.isnull()

df[df["math score"].isnull()]

df[df["math score"].notnull()]

label_encoder = LabelEncoder()
df['gender'] = label_encoder.fit_transform(df["gender"])

df['math score'] = df['math score'].fillna(df['math score'].mean())
df['reading score'] = df['reading score'].fillna(df['reading score'].median())
df['writing score'] = df['writing score'].fillna(df['writing score'].std())
df['Placement Score'] = df['Placement Score'].fillna(df['Placement Score'].min())
df['placement offer count'] = df['placement offer count'].fillna(df['placement offer count'].max())

df.fillna(0, inplace=True)

df

==============================================================

A3:
import pandas as pd
import numpy as np
from sklearn import preprocessing

df = pd.read_csv("Mall_Customers.csv")

df.select_dtypes(include='number').mean()
df[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']].mean(axis=1)[0:4]
df.select_dtypes(include='number').median()
df.select_dtypes(include='number').mode().iloc[0]
df.select_dtypes(include='number').std()


df.groupby(['Genre'])['Age'].mean()
df.groupby(['Genre'])['Age'].median()
df.groupby(['Genre'])['Age'].std()

enc = preprocessing.OneHotEncoder()
enc_df = pd.DataFrame(enc.fit_transform(df[['Genre']]).toarray())

df_encode = df.join(enc_df)
df_encode

iris = pd.read_csv("IRIS.csv")

irisSet = (iris['species'] == 'Iris-setosa')
print('Iris-setosa')
print(iris[irisSet].describe())

irisVer = (iris['species'] == 'Iris-versicolor')
print('Iris-versicolor')
print(iris[irisVer].describe())

irisVir = (iris['species'] == 'Iris-virginica')
print('Iris-virginica')
print(iris[irisVir].describe())

==============================================================

A4:
import pandas as pd
import numpy as np

from sklearn.datasets import fetch_california_housing
housing = fetch_california_housing()
data = pd.DataFrame(housing.data, columns=housing.feature_names)
data['PRICE'] = housing.target

print("Missing values:\n", data.isnull().sum())

X = data.drop('PRICE', axis=1)
y = data['PRICE']

from sklearn.model_selection import train_test_split
xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=0)

from sklearn.linear_model import LinearRegression
model = LinearRegression()
model.fit(xtrain, ytrain)

ytrain_pred = model.predict(xtrain)
ytest_pred = model.predict(xtest)

from sklearn.metrics import mean_squared_error, r2_score
print("Train MSE:", mean_squared_error(ytrain, ytrain_pred))
print("Test MSE:", mean_squared_error(ytest, ytest_pred))
print("Train R2 Score:", r2_score(ytrain, ytrain_pred))
print("Test R2 Score:", r2_score(ytest, ytest_pred))
import matplotlib.pyplot as plt
plt.scatter(ytrain, ytrain_pred, c='blue', label='Train')
plt.scatter(ytest, ytest_pred, c='green', label='Test')
plt.xlabel('Actual Prices')
plt.ylabel('Predicted Prices')
plt.title('Actual vs Predicted Prices')
plt.legend()
plt.show()
==============================================================

A5:
import pandas as pd
import numpy as np

df = pd.read_csv('data5.csv')
df = df.drop("Genre", axis=1)
X = df.iloc[:, :-1].values
y = df.iloc[:, -1].values

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2)

from sklearn.linear_model import LogisticRegression
model = LogisticRegression()
model.fit(X_train, y_train)

from sklearn.metrics import confusion_matrix
y_pred = model.predict(X_test)
tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()

accuracy = (tn + tp) * 100 / (tp + tn + fp + fn)
precision = tp / (tp + fp)
recall = tp / (tp + fn)
f1_score = 2 * precision * recall / (precision + recall)
specificity = tn / (tn + fp)

print(f"Accuracy: {accuracy:.2f}%")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print(f"F1 Score: {f1_score:.2f}")
print(f"Specificity: {specificity:.2f}")

input_values = [float(input(f"Feature {i+1}: ")) for i in range(X_train.shape[1])]
prediction = model.predict(np.array(input_values).reshape(1, -1))[0]
print(f"Predicted Output: {prediction}")

ENTER INPUT:
Feature 1: 35
Feature 2: 60000
Feature 3: 75

==============================================================

A6:
import pandas as pd
import numpy as np

dataset = pd.read_csv('data6.csv')
X, y = dataset.iloc[:, :-1].values, dataset.iloc[:, -1].values

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train, X_test = sc.fit_transform(X_train), sc.transform(X_test)

from sklearn.naive_bayes import GaussianNB
classifier = GaussianNB()
classifier.fit(X_train, y_train)
y_pred = classifier.predict(X_test)

from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix
print(f"Accuracy: {accuracy_score(y_test, y_pred):.2f}")
print(f"Precision: {precision_score(y_test, y_pred, average='micro'):.2f}")
print(f"Recall: {recall_score(y_test, y_pred, average='micro'):.2f}")
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

age = float(input("Enter age: "))
salary = float(input("Enter salary: "))
scaled_input = sc.transform([[age, salary]])
print(f"Predicted class for age {age} and salary {salary}: {classifier.predict(scaled_input)[0]}")

ENTER INPUT (For 1):
AGE: 50
ALARY : 120000

==============================================================

A7:
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from nltk.stem.wordnet import WordNetLemmatizer
from nltk import pos_tag

nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('averaged_perceptron_tagger')

text = """Natural Language Processing is a sub-field of Artificial Intelligence, focused on the interaction between computers and humans."""

# Tokenization
tokens = word_tokenize(text)
print("Tokens:", tokens)

# POS Tagging
pos_tags = pos_tag(tokens)
print("POS Tags:", pos_tags)

# Stopwords removal
stop_words = set(stopwords.words('english'))
filtered_tokens = [word for word in tokens if word.lower() not in stop_words]
print("Filtered Tokens:", filtered_tokens)

# Stemming
ps = PorterStemmer()
stemmed_tokens = [ps.stem(word) for word in filtered_tokens]
print("Stemmed Tokens:", stemmed_tokens)

# Lemmatization
lem = WordNetLemmatizer()
lemmatized_tokens = [lem.lemmatize(word, "v") for word in filtered_tokens]  print("Lemmatized Tokens:", lemmatized_tokens)

==============================================================

A8:
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

dataset = pd.read_csv('train.csv')  
dataset

dataset.info()

dataset.describe()

dataset.dtypes

dataset.isnull().sum()

sns.histplot(dataset['Fare'], kde=False, bins=10)
plt.title('Ticket Price Distribution')
plt.xlabel('Fare')
plt.ylabel('Count')
plt.show()

sns.jointplot(x='Age', y='Fare', data=dataset)
plt.show()

sns.pairplot(dataset)
plt.show()
sns.boxplot(x='Survived', y='Fare', data=dataset)
plt.title('Fare Distribution by Survival')
plt.show()

sns.violinplot(x='Sex', y='Age', data=dataset, hue='Survived')
plt.title('Age Distribution by Sex and Survival')
plt.show()

==============================================================

A9:
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

dataset = pd.read_csv('train.csv')

dataset.head()

sns.boxplot(x='Sex', y='Age', data=dataset)
plt.title('Age Distribution by Sex')
plt.show()

sns.boxplot(x='Sex', y='Age', data=dataset, hue='Survived')
plt.title('Age Distribution by Sex and Survival Status')
plt.show()

==============================================================

A10:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv("iris-flower-dataset (1).csv")
df.columns = ["sepal_length", "sepal_width", "petal_length", "petal_width", "species"]

print(df.head())
print(df.info())
print(np.unique(df["species"]))
print(df.describe())

fig, axes = plt.subplots(2, 2, figsize=(16, 8))

axes[0, 0].set_title("Distribution of Sepal Length")
axes[0, 0].hist(df["sepal_length"], bins=10, color='skyblue', edgecolor='black')

axes[0, 1].set_title("Distribution of Sepal Width")
axes[0, 1].hist(df["sepal_width"], bins=10, color='lightgreen', edgecolor='black')

axes[1, 0].set_title("Distribution of Petal Length")
axes[1, 0].hist(df["petal_length"], bins=10, color='salmon', edgecolor='black')

axes[1, 1].set_title("Distribution of Petal Width")
axes[1, 1].hist(df["petal_width"], bins=10, color='plum', edgecolor='black')

plt.tight_layout()
plt.show()

data_to_plot = [df["sepal_length"], df["sepal_width"], df["petal_length"], df["petal_width"]]
plt.figure(figsize=(10, 6))
plt.title("Boxplots of Numeric Features")
plt.boxplot(data_to_plot, labels=["Sepal Length", "Sepal Width", "Petal Length", "Petal Width"])
plt.grid(True)
plt.show()

==============================================================











